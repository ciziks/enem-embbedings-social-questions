{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36046665",
   "metadata": {},
   "source": [
    "# 1. Extração dos Enunciados das Provas do Enem LEDOR (2015-2023)\n",
    "\n",
    "Este notebook apresenta o processo de extração textual das provas do ENEM adaptadas para acessibilidade, conhecidas como provas LEDOR. Essas versões são destinadas a participantes com deficiência visual e trazem descrições detalhadas de imagens e gráficos, além de uma estrutura mais textual e padronizada.\n",
    "\n",
    "Optamos por utilizar as provas LEDOR ao invés da aplicação regular devido aos seguintes benefícios para a nossa tarefas de PLN e predição:\n",
    "\n",
    "- Enunciados mais completos e com menos dependência de elementos visuais;\n",
    "- Formato mais limpo, facilitando a tokenização, análise semântica e a modelagem textual;\n",
    "- Melhor desempenho na extração automática com bibliotecas como PyMuPDF, em conjunto com regex e revisão manual.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b73d7354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias para extração de texto\n",
    "import re\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader\n",
    "import pymupdf\n",
    "from PIL import Image\n",
    "import io\n",
    "import pytesseract\n",
    "import fitz\n",
    "import os\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f9de7",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.1. Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eec2b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que recebe o caminho do pdf, a página de início e a de fim e retorna as questões\n",
    "def extract_questions(full_text: str, caps_lock: bool = False) -> list[str]:\n",
    "    delimiter = \"QUESTÃO \" if caps_lock else \"Questão \"\n",
    "    sections = full_text.split(delimiter)\n",
    "    questions = [s[3:] for s in sections if s[:2].isnumeric()]\n",
    "    return questions\n",
    "\n",
    "# Extração dos enunciados\n",
    "def get_questions_text(pdf_path: str, start_page: int, end_page: int, caps_lock: bool = False) -> list[str]:\n",
    "    reader = PdfReader(pdf_path)\n",
    "    final_questions = []\n",
    "\n",
    "    for page_num in range(start_page, end_page):\n",
    "        full_text = reader.pages[page_num].extract_text() or \"\"\n",
    "        final_questions.extend(extract_questions(full_text, caps_lock))\n",
    "    return final_questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c04a9eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_questions_2021(full_text: str, caps_lock: bool = False) -> list[str]:\n",
    "#     delimiter = \"QUESTÃO \" if caps_lock else \"Questão \"\n",
    "#     sections = full_text.split(delimiter)\n",
    "#     questions = [s[3:] for s in sections if s[:2].isnumeric()]\n",
    "#     return questions\n",
    "\n",
    "# # Função para processar PDF imagem (com OCR)\n",
    "# def get_questions_text_2021(pdf_path: str, start_page: int, end_page: int, caps_lock: bool = False) -> list[str]:\n",
    "#     pages = convert_from_path(pdf_path, dpi=300)\n",
    "#     final_questions = []\n",
    "\n",
    "#     for i in range(start_page, end_page):\n",
    "#         image = pages[i]\n",
    "#         full_text = pytesseract.image_to_string(image, lang=\"por\") or \"\"\n",
    "        \n",
    "#         rodape_pattern = r\"(\\d+\\s*)?CH\\s*-?\\s*1º\\s*dia\\s*\\|\\s*Caderno\\s*9\\s*-?\\s*LARANJA\\s*LEDO[R]*\\s*-?\\s*1ª?\\s*Aplicação(\\s*\\d+)?\"\n",
    "#         full_text = re.sub(rodape_pattern, \"\", full_text)\n",
    "\n",
    "\n",
    "#         # Remover códigos do rodapé, por exemplo: *020325AZ5*\n",
    "#         full_text = re.sub(r\"\\*\\w+\\*\", \"\", full_text)\n",
    "\n",
    "#         # Remover linhas que contenham apenas dígitos (possíveis números de página)\n",
    "#         full_text = re.sub(r\"\\n\\s*\\d+\\s*$\", \"\", full_text)        \n",
    "\n",
    "#         final_questions.extend(extract_questions_2021(full_text, caps_lock))\n",
    "#         print(full_text)\n",
    "\n",
    "\n",
    "#     return final_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad459e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que retorna as questões sem as alternativas e as alternativas formatadas\n",
    "def format_alternatives(alt: str) -> str:\n",
    "    match = re.search(r\"(A\\s.+?)(B\\s.+?)(C\\s.+?)(D\\s.+?)(E\\s.+)\", alt)\n",
    "    if match:\n",
    "        groups = match.groups()\n",
    "        return \"; \".join([f\"{item[0]}: {item[2:-1]}\" for item in groups])\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def get_alternatives(questions: list[str], filter: bool = False) -> tuple[list[str], list[str]]:\n",
    "    formatted_questions = []\n",
    "    formatted_alternatives = []\n",
    "\n",
    "    for question in questions:\n",
    "        parts = re.split(r\"(\\nA\\s.*\\n)\", question)\n",
    "\n",
    "        alternatives_text = \"\".join(parts[-2:]).replace(\"\\n\", \"\")\n",
    "        alternatives_text = re.sub(r\"\\*.*\\*\", \"\", alternatives_text)\n",
    "        alternatives_text = re.sub(r\"(CH).*\\d\", \"\", alternatives_text)\n",
    "        alternatives = format_alternatives(alternatives_text)\n",
    "\n",
    "        question_text = \"\".join(parts[:-2]).replace(\"\\n\", \"\")\n",
    "\n",
    "        formatted_questions.append(question_text)\n",
    "        formatted_alternatives.append(alternatives)\n",
    "\n",
    "    return formatted_questions, formatted_alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cc87bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que realiza a leitura dos microdados\n",
    "def reading_data(path_to_data: str, year: str, code: int) -> pd.DataFrame:\n",
    "\n",
    "    df = pd.read_csv(path_to_data, sep=';', encoding='latin-1')\n",
    "    \n",
    "    df = df[(df['SG_AREA'] == 'CH') & (df['TX_COR'].str.lower() == 'laranja')]\n",
    "    df = df[df['CO_PROVA'] == code]\n",
    "    df = df[['CO_POSICAO', 'TX_GABARITO', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_C']].copy()\n",
    "    \n",
    "    df['ANO'] = year\n",
    "\n",
    "    return df\n",
    "\n",
    "# Função auxiliar para criar o dataset com as novas colunas\n",
    "\n",
    "def merge_questions_alternatives(dataset: pd.DataFrame, questions: list[str], alts: list[str]) -> pd.DataFrame:\n",
    "    dataset = dataset.sort_values(by=['CO_POSICAO'])\n",
    "    \n",
    "    dataset['QUESTOES'] = questions\n",
    "    dataset['ALTERNATIVAS'] = alts\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07778c8b",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.2. Extração do Texto e Cruzamento com Microdados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b992d913",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = {\n",
    "    2017: (19, 32, True, 408),\n",
    "    2018: (19, 32, True, 464),\n",
    "    2019: (19, 32, False, 520),\n",
    "    2020: (19, 32, False, 574),\n",
    "#     2021: (23, 34, False, 886),\n",
    "    2022: (20, 32, True, 1062),\n",
    "    2023: (19, 32, True, 1198),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bdc821c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo ../data/processed/enem_2017.csv criado com sucesso.\n",
      "Arquivo ../data/processed/enem_2018.csv criado com sucesso.\n",
      "Arquivo ../data/processed/enem_2019.csv criado com sucesso.\n",
      "Arquivo ../data/processed/enem_2020.csv criado com sucesso.\n",
      "Arquivo ../data/processed/enem_2022.csv criado com sucesso.\n",
      "Arquivo ../data/processed/enem_2023.csv criado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "for year, (start_page, end_page, question_caps, code) in years.items():\n",
    "    path_to_microdados = f\"../data/raw/microdados/microdados_{year}.csv\"\n",
    "    path_to_prova = f\"../data/raw/provas/Enem_{year}.pdf\"\n",
    "    output_path = f\"../data/processed/enem_{year}.csv\"\n",
    "\n",
    "    questions = get_questions_text(path_to_prova, start_page, end_page, question_caps)\n",
    "    questions, alternatives = get_alternatives(questions)\n",
    "\n",
    "    \n",
    "    dataset = reading_data(path_to_microdados, year, code)\n",
    "\n",
    "    if year in (2022, 2023):\n",
    "        questions = [question for question in questions if question]\n",
    "        alternatives = [alternative for alternative in alternatives if alternative]\n",
    "        \n",
    "    dataset = merge_questions_alternatives(dataset, questions, alternatives)\n",
    "\n",
    "    dataset = dataset.rename(\n",
    "        columns={\n",
    "            \"CO_POSICAO\": \"numero_questao\",\n",
    "            \"QUESTOES\": \"enunciado\",\n",
    "            \"ALTERNATIVAS\": \"alternativas\",\n",
    "            \"NU_PARAM_B\": \"nu_param_B\",\n",
    "            \"TX_GABARITO\": \"gabarito\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    dataset.to_csv(output_path, sep=\";\", index=False)\n",
    "    print(f\"Arquivo {output_path} criado com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4d54e8",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.3. Exceção: Prova de 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63a8ddf7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# input_path = \"../data/raw/provas/Enem_2021.pdf\"\n",
    "\n",
    "# doc = pymupdf.open(input_path)\n",
    "\n",
    "# texto_total = \"\"\n",
    "\n",
    "# for pagina in doc[23:34]:\n",
    "#     # Renderiza a página como imagem\n",
    "#     pix = pagina.get_pixmap(dpi=300)\n",
    "#     img = Image.open(io.BytesIO(pix.tobytes()))\n",
    "\n",
    "#     # OCR para extrair texto da imagem\n",
    "#     texto = pytesseract.image_to_string(img, lang=\"por\")\n",
    "#     texto_total += texto + \"\\n\"\n",
    "#     print('teste')\n",
    "\n",
    "# doc.close()\n",
    "\n",
    "# # Remover o rodapé com variações\n",
    "# rodape_pattern = r\"(\\d+\\s*)?CH\\s*-?\\s*1º\\s*dia\\s*\\|\\s*Caderno\\s*9\\s*-?\\s*LARANJA\\s*LEDO[R]*\\s*-?\\s*1ª?\\s*Aplicação(\\s*\\d+)?\"\n",
    "# full_text = re.sub(rodape_pattern, \"\", full_text)\n",
    "\n",
    "\n",
    "# # Remover códigos do rodapé, por exemplo: *020325AZ5*\n",
    "# full_text = re.sub(r\"\\*\\w+\\*\", \"\", full_text)\n",
    "\n",
    "# # Remover linhas que contenham apenas dígitos (possíveis números de página)\n",
    "# full_text = re.sub(r\"\\n\\s*\\d+\\s*$\", \"\", full_text)\n",
    "\n",
    "# # Dividindo o texto em blocos de questões\n",
    "\n",
    "# question_blocks = re.split(r\"QUESTÃO\\s+\", full_text)\n",
    "# question_blocks = [block.strip() for block in question_blocks if block.strip()]\n",
    "\n",
    "# results = []\n",
    "\n",
    "# print(full_text)\n",
    "\n",
    "# for block in question_blocks:\n",
    "#     # Extraindo número da questão\n",
    "#     m = re.match(r\"(\\d+)\", block)\n",
    "#     if not m:\n",
    "#         continue\n",
    "#     num_quest = m.group(1)\n",
    "\n",
    "#     content = block[m.end() :].strip()\n",
    "\n",
    "#     content = content.replace(\"\\x03\", \"\").replace(\"\\x0f\", \"\").replace(\"\\x11\", \"\")\n",
    "\n",
    "#     # Separando enunciado e alternativas.\n",
    "#     padrao = r\"(A[^\\n]*\\n.*?\\nB[^\\n]*\\n.*?\\nC[^\\n]*\\n.*?\\nD[^\\n]*\\n.*?\\nE[^\\n]*\\n.*?)(?=\\n\\n|\\Z)\"\n",
    "#     match = re.search(padrao, content, flags=re.DOTALL)\n",
    "#     if match:\n",
    "#         enunciado = content[: match.start()].strip()\n",
    "#         alt_text = match.group(0).strip()\n",
    "#     else:\n",
    "#         enunciado = content\n",
    "#         alt_text = \"\"\n",
    "\n",
    "#     # Extraindo alternativas\n",
    "#     alt_regex = r\"\\b([A-E])\\b[\\s\\-\\.:]*([\\s\\S]*?)(?=\\n[A-E]\\b[\\s\\-\\.:]|$)\"\n",
    "#     alt_raw = re.findall(alt_regex, alt_text, flags=re.DOTALL)\n",
    "\n",
    "#     # Formatando alternativas como \"A: texto\"\n",
    "#     alternativas = \"; \".join(\n",
    "#         [f\"{letter}: {text.strip()}\" for letter, text in alt_raw]\n",
    "#     )\n",
    "#     results.append(\n",
    "#         {\n",
    "#             \"numero_questao\": num_quest,\n",
    "#             \"enunciado\": enunciado,\n",
    "#             \"alternativas\": alternativas,\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "# # with open(output_path, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "# #     fieldnames = [\"numero_questao\", \"enunciado\", \"alternativas\"]\n",
    "# #     writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "# #     writer.writeheader()\n",
    "# #     for row in results:\n",
    "# #         writer.writerow(row)\n",
    "\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4879548b",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.4. Unindo Todos os Dados em Único Arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7652ade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {}\n",
    "output_path = \"../data/final/enem_data.csv\"\n",
    "\n",
    "for year in years:\n",
    "    df_path = f\"../data/processed/enem_{year}.csv\"\n",
    "    df = pd.read_csv(df_path, encoding=\"utf-8\", quotechar='\"', sep=';', index_col=0)\n",
    "    dataframes[year] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4616440",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat(dataframes.values(), axis=0)\n",
    "\n",
    "df_final.to_csv(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
