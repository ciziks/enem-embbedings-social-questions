{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análise Exploratória dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_folder = \"../data/cleaned_data.csv\"\n",
    "\n",
    "# Carregando dados limpos (resultado da Pré-Tokenização)\n",
    "df_enem = pd.read_csv(data_folder)\n",
    "df_enem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "df = df_enem.rename(columns={\"nu_param_B\": \"dificuldade\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Preliminar\n",
    "\n",
    "Dado que `nu_param_B` (aka. `dificuldade`, por aqui) é a variável target, desnecessário focar em questões em que esta não foi calculada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['dificuldade'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Análise da Dificuldade**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['dificuldade'], bins=30, kde=True)\n",
    "plt.title('Distribuição da Dificuldade')\n",
    "plt.xlabel('Dificuldade')\n",
    "plt.ylabel('Frequência')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(df['dificuldade'], dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot (Dificuldade)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = stats.shapiro(df[df['dificuldade'].notna()]['dificuldade'])\n",
    "print(f\"Estatística de teste: {stat:.4f} | p-valor: {p:.4f}\")\n",
    "\n",
    "if p > 0.05:\n",
    "    print(\"Não rejeita H_0: distribuição normal.\")\n",
    "else:\n",
    "    print(\"Rejeita H_0: exclui distribuição normal.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a exclusão da distribuição normal, necessário o grupo se atentar se o modelo de predição possui sensibilidade à distribuição. \n",
    "\n",
    "Caso seja, possível aplicar Box-Cox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='ano', y='dificuldade', data=df, order=sorted(df[\"ano\"].unique()))\n",
    "plt.title('Dificuldade por Ano')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_sem_outlier(group):\n",
    "    Q1 = group.quantile(0.25)\n",
    "    Q3 = group.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    return group[group <= limite_superior].max()  \n",
    "\n",
    "max_por_ano = df.groupby('ano')['dificuldade'].apply(max_sem_outlier)\n",
    "max_por_ano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O corte de dificuldade 3, feito no artigo, não parece de todo arbitrário.\n",
    "\n",
    "Afinal, na maioria dos anos, o máximo de dificuldade (excluídos os outliers) não ultrapassa 3 frequentemente. Como sugestão, possível utilizar o corte do máximo da lista (ano de 2013, com 3.38570)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Análise enunciados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "df['tam_enunciado'] = df['enunciado'].str.len()\n",
    "df['tam_enunciado_limpo'] = df['enunciado_limpo'].str.len()\n",
    "\n",
    "sns.histplot(df['tam_enunciado'], bins=30, kde=True, ax=axes[0])\n",
    "axes[0].set_title('Distribuição do Tamanho dos Enunciados')\n",
    "\n",
    "sns.histplot(df['tam_enunciado_limpo'], bins=30, kde=True, ax=axes[1])\n",
    "axes[1].set_title('Distribuição do Tamanho dos Enunciados (sem stop word)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "sns.scatterplot(x='tam_enunciado', y='dificuldade', data=df, ax=axes[0])\n",
    "axes[0].set_title('Tamanho do Enunciado vs Dificuldade')\n",
    "\n",
    "sns.scatterplot(x='tam_enunciado_limpo', y='dificuldade', data=df, ax=axes[1])\n",
    "axes[1].set_title('Tamanho do Enunciado vs Dificuldade (sem stop word)')\n",
    "\n",
    "x_min = df['tam_enunciado_limpo'].min()\n",
    "x_max = df['tam_enunciado'].max()\n",
    "axes[0].set_xlim(x_min, x_max)\n",
    "axes[1].set_xlim(x_min, x_max)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não se verifica um correlação direta entre o tamanho do enunciado e a dificuldade da questão, muito embora se verifique uma pequena concentração entre 0 e 2 nos menores enunciados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Análise de Gabarito**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gabarito'].value_counts().plot(kind='bar', title='Distribuição de Alternativas Corretas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "df['tam_alternativas'] = df['alternativas'].str.len()\n",
    "df['tam_alternativas_limpo'] = df['alternativas_limpo'].str.len()\n",
    "\n",
    "sns.histplot(df['tam_alternativas'], bins=30, kde=True, ax=axes[0])\n",
    "axes[0].set_title('Distribuição do Tamanho das Alternativass')\n",
    "\n",
    "sns.histplot(df['tam_alternativas_limpo'], bins=30, kde=True, ax=axes[1])\n",
    "axes[1].set_title('Distribuição do Tamanho das Alternativass (sem stop word)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "sns.scatterplot(x='tam_alternativas', y='dificuldade', data=df, ax=axes[0])\n",
    "axes[0].set_title('Tamanho das Alternativas vs Dificuldade')\n",
    "\n",
    "sns.scatterplot(x='tam_alternativas_limpo', y='dificuldade', data=df, ax=axes[1])\n",
    "axes[1].set_title('Tamanho das Alternativas vs Dificuldade (sem stop word)')\n",
    "\n",
    "x_min = df['tam_alternativas_limpo'].min()\n",
    "x_max = df['tam_alternativas'].max()\n",
    "axes[0].set_xlim(x_min, x_max)\n",
    "axes[1].set_xlim(x_min, x_max)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordCloud (Gabarito e Alternativas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordcloud(df, col):\n",
    "    # 1. Filtrar os dados\n",
    "    df_counter = df.dropna(subset=[col])  # Remove NaN\n",
    "    median_dif = df_counter['dificuldade'].median()\n",
    "\n",
    "    # 2. Textos para cada grupo\n",
    "    text_total = ' '.join(df_counter[col])\n",
    "    text_hard = ' '.join(df_counter[df_counter['dificuldade'] > median_dif][col])\n",
    "    text_easy = ' '.join(df_counter[df_counter['dificuldade'] <= median_dif][col])\n",
    "\n",
    "    # 3. Configurar as nuvens\n",
    "    wordcloud_total = WordCloud(width=600, height=300, background_color='white').generate(text_total)\n",
    "    wordcloud_hard = WordCloud(width=600, height=300, background_color='white').generate(text_hard)\n",
    "    wordcloud_easy = WordCloud(width=600, height=300, background_color='white').generate(text_easy)\n",
    "\n",
    "    # 4. Plotar em uma linha\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    # Nuvem 1: Total\n",
    "    axes[0].imshow(wordcloud_total, interpolation='bilinear')\n",
    "    axes[0].set_title('Todos os Enunciados', fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Nuvem 2: Maior dificuldade\n",
    "    axes[1].imshow(wordcloud_hard, interpolation='bilinear')\n",
    "    axes[1].set_title(f'Maior Dificuldade ( > {median_dif:.2f})', fontsize=12)\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # Nuvem 3: Menor dificuldade\n",
    "    axes[2].imshow(wordcloud_easy, interpolation='bilinear')\n",
    "    axes[2].set_title(f'Menor Dificuldade ( ≤ {median_dif:.2f})', fontsize=12)\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_frequencies(df, col, top_n = 10):\n",
    "    # 1. Filtrar os dados\n",
    "    df_counter = df.dropna(subset=[col])\n",
    "    median_dif = df_counter['dificuldade'].median()\n",
    "\n",
    "    # 2. Definir os grupos\n",
    "    text_total = df_counter[col]\n",
    "    text_hard = df_counter[df_counter['dificuldade'] > median_dif][col]\n",
    "    text_easy = df_counter[df_counter['dificuldade'] <= median_dif][col]\n",
    "\n",
    "    # 3. Contar palavras (top 10 em cada grupo)\n",
    "    def get_top_words(text_series, n=top_n):\n",
    "        vectorizer = CountVectorizer()\n",
    "        X = vectorizer.fit_transform(text_series)\n",
    "        word_counts = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out()).sum()\n",
    "        return word_counts.sort_values(ascending=False).head(n)\n",
    "\n",
    "    top_total = get_top_words(text_total)\n",
    "    top_hard = get_top_words(text_hard)\n",
    "    top_easy = get_top_words(text_easy)\n",
    "\n",
    "    # 4. Plotar histogramas lado a lado\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "    # Histograma 1: Total\n",
    "    axes[0].barh(top_total.index, top_total.values, color='skyblue')\n",
    "    axes[0].set_title('Todos os Enunciados')\n",
    "    axes[0].invert_yaxis()\n",
    "\n",
    "    # Histograma 2: Alta dificuldade\n",
    "    axes[1].barh(top_hard.index, top_hard.values, color='salmon')\n",
    "    axes[1].set_title(f'Maior Dificuldade ( > {median_dif:.2f})')\n",
    "\n",
    "    # Histograma 3: Baixa dificuldade\n",
    "    axes[2].barh(top_easy.index, top_easy.values, color='lightgreen')\n",
    "    axes[2].set_title(f'Menor Dificuldade ( ≤ {median_dif:.2f})')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_wordcloud(df, \"enunciado_limpo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_word_frequencies(df, \"enunciado_limpo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['alternativas_adap'] = df['alternativas_limpo'].dropna().str.replace(r'[A-E]:\\s*', '', regex=True)\n",
    "\n",
    "get_wordcloud(df, \"alternativas_adap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_word_frequencies(df, \"alternativas_adap\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
