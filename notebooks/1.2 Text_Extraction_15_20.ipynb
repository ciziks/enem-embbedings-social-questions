{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Extração do Texto das Provas do ENEM 2015 - 2020\n",
    "\n",
    "* **Input**: arquivos PDFs das provas dos respectivos anos + Arquivos CSV com microdados dos respectivos anos\n",
    "\n",
    "* **Output**: CSV com a extração dos dados mantendo as colunas originais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vRDZIVmnRt_6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pymupdf\n",
    "\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0zLyt49Rt_-"
   },
   "source": [
    "# Funções Utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VZRONvjzSJt_"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# função que realiza a leitura dos microdados\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreading_data\u001b[39m(path_to_data: \u001b[38;5;28mstr\u001b[39m, year: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m      5\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(path_to_data, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin-1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m     df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSG_AREA\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCH\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTX_COR\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mazul\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# função que realiza a leitura dos microdados\n",
    "\n",
    "def reading_data(path_to_data: str, year: str) -> pd.DataFrame:\n",
    "\n",
    "    df = pd.read_csv(path_to_data, sep=';', encoding='latin-1')\n",
    "    \n",
    "    df = df[(df['SG_AREA'] == 'CH') & (df['TX_COR'].str.lower() == 'azul')]\n",
    "    df = df[df['CO_PROVA'] == df['CO_PROVA'].min()]\n",
    "    df = df[['CO_POSICAO', 'TX_GABARITO', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_C']].copy()\n",
    "    \n",
    "    df['ANO'] = year\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RtcRNTq9RuAP"
   },
   "outputs": [],
   "source": [
    "# Função que recebe o caminho do pdf, a página de início e a de fim e retorna as questões\n",
    "\n",
    "\n",
    "def extract_questions(full_text: str, caps_lock: bool = False) -> list[str]:\n",
    "    delimiter = \"QUESTÃO \" if caps_lock else \"Questão \"\n",
    "    sections = full_text.split(delimiter)\n",
    "    questions = [s[3:] for s in sections if s[:2].isnumeric()]\n",
    "    return questions\n",
    "\n",
    "\n",
    "def get_questions(pdf_path: str, start_page: int, end_page: int, caps_lock: bool = False) -> list[str]:\n",
    "    reader = PdfReader(pdf_path)\n",
    "    final_questions = []\n",
    "\n",
    "    for page_num in range(start_page, end_page):\n",
    "        full_text = reader.pages[page_num].extract_text() or \"\"\n",
    "        final_questions.extend(extract_questions(full_text, caps_lock))\n",
    "\n",
    "    return final_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yIHcM_ehU9A_"
   },
   "outputs": [],
   "source": [
    "# Função que retorna as questões sem as alternativas e as alternativas formatadas\n",
    "\n",
    "def format_alt(alt: str) -> str:\n",
    "    match = re.search(r\"(A\\s.+?)(B\\s.+?)(C\\s.+?)(D\\s.+?)(E\\s.+)\", alt)\n",
    "    if match:\n",
    "        groups = match.groups()\n",
    "        return '; '.join([f\"{item[0]}: {item[2:-1]}\" for item in groups])\n",
    "    return ''\n",
    "\n",
    "def get_alternatives(questions: list[str]) -> tuple[list[str], list[str]]:\n",
    "    formatted_questions = []\n",
    "    formatted_alternatives = []\n",
    "\n",
    "    for question in questions:\n",
    "        parts = re.split(r\"(\\nA\\s.*\\n)\", question)\n",
    "\n",
    "        alternatives_text = ''.join(parts[-2:]).replace('\\n', '')\n",
    "        alternatives_text = re.sub(r\"\\*.*\\*\", \"\", alternatives_text)\n",
    "        alternatives_text = re.sub(r\"(CH).*\\d\", \"\", alternatives_text)\n",
    "        alternatives = format_alt(alternatives_text)\n",
    "\n",
    "        question_text = ''.join(parts[:-2]).replace('\\n', '')\n",
    "\n",
    "        formatted_questions.append(question_text)\n",
    "        formatted_alternatives.append(alternatives)\n",
    "\n",
    "    return formatted_questions, formatted_alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHVP8j_MVW9u"
   },
   "outputs": [],
   "source": [
    "# Função auxiliar para criar o dataset com as novas colunas\n",
    "\n",
    "def merge_quests_alts(dataset: pd.DataFrame, questions: list[str], alts: list[str]) -> pd.DataFrame:\n",
    "    dataset['QUESTOES'] = questions\n",
    "    dataset['ALTERNATIVAS'] = alts\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0zLyt49Rt_-"
   },
   "source": [
    "# Leitura dos Microdados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015 = reading_data('../data/microdados/microdados_2015.csv', '2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = reading_data('../data/microdados/microdados_2015.csv', '2016')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017 = reading_data('../data/microdados/microdados_2015.csv', '2017')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zrRNEu9RuAO"
   },
   "source": [
    "# Leituras da Provas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B0f1-hptRuAO"
   },
   "outputs": [],
   "source": [
    "# Caminho da prova ENEM 2015\n",
    "prova_2015 = '../data/provas/ENEM_2015.pdf'\n",
    "\n",
    "# Caminho da prova ENEM 2016\n",
    "prova_2016 = '../data/provas/ENEM_2016.pdf'\n",
    "\n",
    "# Caminho da prova ENEM 2027\n",
    "prova_2017 = '../data/provas/ENEM_2017.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IaV2oDrkRuAQ",
    "outputId": "619ab99f-15a8-4ea3-96bf-ce499fe85d73"
   },
   "outputs": [],
   "source": [
    "questoes_2015 = get_questions(prova_2015, 1, 15, True)\n",
    "len(questoes_2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6JSVhNdgRuAS",
    "outputId": "ae11430b-0978-4f9a-9f4f-3b099ab914f1"
   },
   "outputs": [],
   "source": [
    "questoes_2016 = get_questions(prova_2016, 1, 15, True)\n",
    "len(questoes_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sbGGA9KjRuAT",
    "outputId": "6c095be8-e8fa-4cc4-c40a-23bbc9d6e22f"
   },
   "outputs": [],
   "source": [
    "questoes_2017 = get_questions(prova_2017, 19, 32, True)\n",
    "len(questoes_2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8WHbGDbRuAU"
   },
   "source": [
    "## Alternativas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "975jab2IRuAV"
   },
   "source": [
    "**2015**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8tYUk_lgRuAW",
    "outputId": "fdd6803e-2826-4590-b9f6-3f5b221c1488"
   },
   "outputs": [],
   "source": [
    "questoes_2015, alts_2015 = get_alternatives(questoes_2015)\n",
    "alts_2015[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02ZgWYEcRuAW"
   },
   "source": [
    "**2016**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7azUy2STRuAX",
    "outputId": "8d1dc92f-e3f3-4f7a-8e0b-168d638d8136"
   },
   "outputs": [],
   "source": [
    "questoes_2016, alts_2016 = get_alternatives(questoes_2016)\n",
    "alts_2016[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TL39HOWpRuAX"
   },
   "source": [
    "**2017**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Gwj4-6CRuAY",
    "outputId": "1f4bcc8d-7897-4b7d-8ee2-d7adbd351a64"
   },
   "outputs": [],
   "source": [
    "questoes_2017, alts_2017 = get_alternatives(questoes_2017)\n",
    "alts_2017[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6kKv2TvRuAZ"
   },
   "source": [
    "# Montando o dataset final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRWH8YBURuAZ",
    "outputId": "df8031b2-b715-4e1e-d414-dd6d7a20948e"
   },
   "outputs": [],
   "source": [
    "df_final = pd.concat([merge_quests_alts(df_2015, questoes_2015, alts_2015),\n",
    "                      merge_quests_alts(df_2016, questoes_2016, alts_2016),\n",
    "                      merge_quests_alts(df_2017, questoes_2017, alts_2017)], axis=0)\n",
    "\n",
    "df_final.to_csv('df_15-17.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
